name: CI

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master, develop ]
  workflow_dispatch:

env:
  GO_VERSION: 1.24
  COVERAGE_THRESHOLD: 90

jobs:
  # Code quality checks
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Install dependencies
      run: make deps

    - name: Run code quality checks
      run: make check

    - name: Install golangci-lint
      run: |
        curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin latest

    - name: Run golangci-lint
      run: golangci-lint run --timeout 5m

    - name: Install gosec
      run: |
        go install github.com/securego/gosec/v2/cmd/gosec@latest

    - name: Run security scan with gosec
      run: |
        echo "Running security analysis..."
        gosec -severity medium -confidence high -fmt json -out security-report.json ./... || true
        gosec -severity high -confidence medium -fmt text ./...

  # Unit and integration tests
  test:
    name: Tests
    runs-on: ubuntu-latest
    needs: quality
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Install dependencies
      run: make deps

    - name: Run tests with coverage
      run: |
        sudo apt-get update
        sudo apt-get install -y bc jq
        ./scripts/test.sh -t all -c -v --threshold ${{ env.COVERAGE_THRESHOLD }}
      env:
        CI: true

    - name: Generate comprehensive coverage reports
      run: |
        ./scripts/coverage.sh --format all --threshold ${{ env.COVERAGE_THRESHOLD }} --ci
      env:
        CI: true

    - name: Generate coverage dashboard
      run: |
        ./test/coverage/dashboard.sh -v
      env:
        CI: true

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage/coverage.out
        flags: unittests
        name: codecov-umbrella

    - name: Create coverage badge
      run: |
        if [ -f coverage/coverage.json ]; then
          COVERAGE=$(jq -r '.overall.coverage' coverage/coverage.json)
          echo "COVERAGE=$COVERAGE" >> $GITHUB_ENV
        fi

    - name: Comment coverage on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          try {
            const coverageData = JSON.parse(fs.readFileSync('coverage/coverage.json', 'utf8'));
            const overall = coverageData.overall;
            
            const comment = `## 📊 Coverage Report
            
            **Overall Coverage:** ${overall.coverage}%
            **Threshold:** ${overall.threshold}%
            **Status:** ${overall.status === 'PASS' ? '✅ PASS' : '❌ FAIL'}
            
            ### Module Coverage
            ${Object.entries(coverageData.packages || {})
              .slice(0, 10)
              .map(([pkg, data]) => `- \`${pkg}\`: ${data.coverage}% ${data.status === 'PASS' ? '✅' : '❌'}`)
              .join('\n')}
            ${Object.keys(coverageData.packages || {}).length > 10 ? '\n_...and more modules_' : ''}
            
            ### Critical Modules
            ${Object.entries(coverageData.critical_modules || {})
              .map(([pkg, data]) => `- \`${pkg}\`: ${data.coverage}% ${data.status === 'PASS' ? '✅' : '❌'}`)
              .join('\n')}
            
            ${overall.status === 'PASS' ? 
              '🎉 All coverage thresholds met!' : 
              '⚠️ Coverage thresholds not met. Please add more tests.'}
            
            📋 [View detailed coverage dashboard](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } catch (error) {
            console.error('Error creating coverage comment:', error);
          }

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results
        path: |
          coverage/
          test-reports/

    - name: Upload coverage dashboard
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: coverage-dashboard
        path: coverage/dashboard/
        retention-days: 30

  # Build binaries for multiple platforms
  build:
    name: Build
    runs-on: ubuntu-latest
    needs: [quality, test]
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64
          - goos: darwin
            goarch: amd64
          - goos: darwin
            goarch: arm64
          - goos: windows
            goarch: amd64
          - goos: windows
            goarch: arm64
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Install dependencies
      run: make deps

    - name: Build binary
      run: make build-${{ matrix.goos }}-${{ matrix.goarch }}

    - name: Upload binary
      uses: actions/upload-artifact@v4
      with:
        name: lsp-gateway-${{ matrix.goos }}-${{ matrix.goarch }}
        path: dist/lsp-gateway-${{ matrix.goos }}-${{ matrix.goarch }}*


  # Release (only on tags)
  release:
    name: Release
    runs-on: ubuntu-latest
    needs: [quality, test, build]
    if: startsWith(github.ref, 'refs/tags/v')
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        path: artifacts

    - name: Prepare release assets
      run: |
        mkdir -p dist
        find artifacts -name "lsp-gateway-*" -type f -exec cp {} dist/ \;
        cd dist
        for file in lsp-gateway-*; do
          if [ -f "$file" ]; then
            sha256sum "$file" > "$file.sha256"
          fi
        done

    - name: Generate changelog
      id: changelog
      run: |
        # Extract version from tag
        VERSION=${GITHUB_REF#refs/tags/}
        echo "version=$VERSION" >> $GITHUB_OUTPUT
        
        # Generate changelog (you can customize this)
        cat > RELEASE_NOTES.md << EOF
        # LSP Gateway $VERSION
        
        ## What's New
        
        This release includes improvements to the LSP Gateway functionality.
        
        ## Installation
        
        Download the appropriate binary for your platform from the release assets below.
        
        ## Verification
        
        Each binary includes a SHA256 checksum file for verification.
        EOF

    - name: Create GitHub Release
      uses: softprops/action-gh-release@v2
      with:
        name: LSP Gateway ${{ steps.changelog.outputs.version }}
        body_path: RELEASE_NOTES.md
        files: |
          dist/*
        draft: false
        prerelease: false
        generate_release_notes: true
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Performance benchmarks
  benchmark:
    name: Benchmarks
    runs-on: ubuntu-latest
    needs: quality
    if: github.event_name == 'pull_request'
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Install dependencies
      run: make deps

    - name: Run benchmarks
      run: make bench > benchmark.txt

    - name: Comment PR with benchmarks
      uses: actions/github-script@v7
      if: github.event_name == 'pull_request'
      with:
        script: |
          const fs = require('fs');
          const benchmark = fs.readFileSync('benchmark.txt', 'utf8');
          
          const body = `## Benchmark Results
          
          \`\`\`
          ${benchmark}
          \`\`\`
          `;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: body
          });

  # LSP Validation - Quick mode for PRs
  lsp-validation-quick:
    name: LSP Validation (Quick)
    runs-on: ubuntu-latest
    needs: quality
    if: github.event_name == 'pull_request'
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Install dependencies
      run: make deps

    - name: Setup test environment
      run: |
        sudo apt-get update
        sudo apt-get install -y bc jq
        # Install language servers for testing
        go install golang.org/x/tools/gopls@latest
        pip3 install python-lsp-server
        npm install -g typescript-language-server typescript

    - name: Build LSP Gateway
      run: make local

    - name: Run quick LSP validation
      run: |
        ./bin/lsp-gateway test-lsp \
          --config=test-configs/ci-test-config.yaml \
          --format=json \
          --output-dir=lsp-results \
          --filter="method=textDocument/definition,textDocument/hover" \
          --timeout=60s \
          --max-concurrency=2 \
          --quick-mode
      env:
        CI: true

    - name: Process LSP validation results
      run: |
        if [ -f lsp-results/results.json ]; then
          # Extract summary statistics
          jq -r '.summary' lsp-results/results.json > lsp-results/summary.txt
          
          # Create performance report
          jq -r '.performance.total_duration' lsp-results/results.json > lsp-results/duration.txt
          echo "LSP_DURATION=$(cat lsp-results/duration.txt)" >> $GITHUB_ENV
          
          # Extract pass/fail counts
          TOTAL_TESTS=$(jq -r '.summary.total_tests' lsp-results/results.json)
          PASSED_TESTS=$(jq -r '.summary.passed_tests' lsp-results/results.json)
          FAILED_TESTS=$(jq -r '.summary.failed_tests' lsp-results/results.json)
          
          echo "LSP_TOTAL=$TOTAL_TESTS" >> $GITHUB_ENV
          echo "LSP_PASSED=$PASSED_TESTS" >> $GITHUB_ENV
          echo "LSP_FAILED=$FAILED_TESTS" >> $GITHUB_ENV
        fi

    - name: Comment LSP validation results on PR
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          try {
            const results = JSON.parse(fs.readFileSync('lsp-results/results.json', 'utf8'));
            const summary = results.summary;
            const performance = results.performance;
            
            // Get failed tests details
            const failedTests = results.test_results
              .filter(test => !test.passed)
              .slice(0, 5); // Show max 5 failed tests
            
            const failureDetails = failedTests.length > 0 ? 
              failedTests.map(test => `- **${test.name}**: ${test.error || 'Unknown error'}`).join('\n') :
              '';
            
            const comment = `## 🔍 LSP Validation Results (Quick Mode)
            
            **Status:** ${summary.passed_tests === summary.total_tests ? '✅ PASSED' : '❌ FAILED'}
            **Total Tests:** ${summary.total_tests}
            **Passed:** ${summary.passed_tests} ✅
            **Failed:** ${summary.failed_tests} ❌
            **Duration:** ${performance.total_duration}
            
            ### Performance Metrics
            - **Average Response Time:** ${performance.avg_response_time}ms
            - **Server Startup Time:** ${performance.server_startup_time}ms
            - **Total Requests:** ${performance.total_requests}
            
            ${failedTests.length > 0 ? `### Failed Tests\n${failureDetails}` : ''}
            ${summary.failed_tests > 5 ? `\n_...and ${summary.failed_tests - 5} more failures_` : ''}
            
            📋 [View detailed LSP validation report](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } catch (error) {
            console.error('Error creating LSP validation comment:', error);
          }

    - name: Upload LSP validation artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: lsp-validation-quick-results
        path: |
          lsp-results/
        retention-days: 7

    - name: Fail on LSP validation errors
      run: |
        if [ -f lsp-results/results.json ]; then
          FAILED_TESTS=$(jq -r '.summary.failed_tests' lsp-results/results.json)
          if [ "$FAILED_TESTS" != "0" ]; then
            echo "❌ LSP validation failed with $FAILED_TESTS failures"
            exit 1
          fi
        fi

  # LSP Validation - Comprehensive mode for main branch
  lsp-validation-comprehensive:
    name: LSP Validation (Comprehensive)  
    runs-on: ubuntu-latest
    needs: [quality, test]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' || github.ref == 'refs/heads/develop')
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Install dependencies
      run: make deps

    - name: Setup comprehensive test environment
      run: |
        sudo apt-get update
        sudo apt-get install -y bc jq python3-pip nodejs npm default-jdk
        
        # Install all language servers
        go install golang.org/x/tools/gopls@latest
        pip3 install python-lsp-server
        npm install -g typescript-language-server typescript
        
        # Setup Java LSP (Eclipse JDT)
        ./scripts/setup-test-environment.sh --install-jdtls

    - name: Build LSP Gateway
      run: make local

    - name: Clone test repositories
      run: |
        ./scripts/clone-repos.sh --max-repos=3 --size-limit=100MB
      env:
        CI: true

    - name: Run comprehensive LSP validation
      run: |
        ./bin/lsp-gateway test-lsp \
          --config=test-configs/integration-test-config.yaml \
          --format=json,junit \
          --output-dir=lsp-results \
          --timeout=600s \
          --max-concurrency=4 \
          --comprehensive-mode \
          --include-repos=golang,python,typescript \
          --benchmark-mode
      env:
        CI: true

    - name: Generate LSP performance report
      run: |
        if [ -f lsp-results/results.json ]; then
          # Generate performance dashboard
          ./internal/testing/lsp/reporters/performance-dashboard.sh \
            --input=lsp-results/results.json \
            --output=lsp-results/dashboard \
            --format=html,json
          
          # Generate benchmark comparison if previous results exist
          if [ -f lsp-results/benchmark-baseline.json ]; then
            ./internal/testing/lsp/reporters/benchmark-compare.sh \
              --baseline=lsp-results/benchmark-baseline.json \
              --current=lsp-results/results.json \
              --output=lsp-results/benchmark-comparison.json
          fi
          
          # Save current results as new baseline
          cp lsp-results/results.json lsp-results/benchmark-baseline.json
        fi

    - name: Upload LSP validation results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: lsp-validation-comprehensive-results
        path: |
          lsp-results/
        retention-days: 30

    - name: Upload LSP performance dashboard
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: lsp-performance-dashboard
        path: |
          lsp-results/dashboard/
        retention-days: 30

    - name: Publish test results
      uses: dorny/test-reporter@v1
      if: success() || failure()
      with:
        name: LSP Validation Results
        path: lsp-results/junit.xml
        reporter: java-junit
        fail-on-error: true

  # Repository validation - Test against real-world repositories
  lsp-repository-validation:
    name: Repository Validation
    runs-on: ubuntu-latest
    needs: [quality, test]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    strategy:
      matrix:
        repo-type: [golang, python, typescript, java]
        include:
          - repo-type: golang
            test-config: test-configs/go-repo-config.yaml
          - repo-type: python  
            test-config: test-configs/python-repo-config.yaml
          - repo-type: typescript
            test-config: test-configs/typescript-repo-config.yaml
          - repo-type: java
            test-config: test-configs/java-repo-config.yaml
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Install dependencies
      run: make deps

    - name: Setup environment for ${{ matrix.repo-type }}
      run: |
        case "${{ matrix.repo-type }}" in
          golang)
            go install golang.org/x/tools/gopls@latest
            ;;
          python)
            sudo apt-get update && sudo apt-get install -y python3-pip
            pip3 install python-lsp-server
            ;;
          typescript)
            sudo apt-get update && sudo apt-get install -y nodejs npm
            npm install -g typescript-language-server typescript
            ;;
          java)
            sudo apt-get update && sudo apt-get install -y default-jdk
            ./scripts/setup-test-environment.sh --install-jdtls
            ;;
        esac

    - name: Build LSP Gateway
      run: make local

    - name: Test against ${{ matrix.repo-type }} repositories
      run: |
        ./bin/lsp-gateway test-lsp \
          --config=${{ matrix.test-config }} \
          --format=json \
          --output-dir=repo-validation-${{ matrix.repo-type }} \
          --timeout=300s \
          --repository-mode
      env:
        CI: true

    - name: Upload repository validation results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: repository-validation-${{ matrix.repo-type }}
        path: |
          repo-validation-${{ matrix.repo-type }}/
        retention-days: 14

  # Cleanup
  cleanup:
    name: Cleanup
    runs-on: ubuntu-latest
    needs: [quality, test, build, lsp-validation-quick, lsp-validation-comprehensive, lsp-repository-validation]
    if: always()
    steps:
    - name: Delete old artifacts
      uses: actions/github-script@v7
      with:
        script: |
          const artifacts = await github.rest.actions.listArtifactsForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            per_page: 100
          });
          
          const oldArtifacts = artifacts.data.artifacts
            .filter(artifact => {
              const createdAt = new Date(artifact.created_at);
              const daysOld = (Date.now() - createdAt) / (1000 * 60 * 60 * 24);
              return daysOld > 30; // Keep artifacts for 30 days
            })
            .slice(0, 10); // Delete max 10 at a time
          
          for (const artifact of oldArtifacts) {
            console.log(`Deleting artifact: ${artifact.name}`);
            await github.rest.actions.deleteArtifact({
              owner: context.repo.owner,
              repo: context.repo.repo,
              artifact_id: artifact.id
            });
          }